{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install neo4j sentence_transformers pandas nltk hdbscan spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727fb704df2cbfe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Build our dataset from Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47932ddc9b0b594",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import textwrap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "NEO4J_URI = \"bolt://neo4j.neo4j.svc.cluster.local\"\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = 'neo4j'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8e87f9f459798",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "auth = (\"neo4j\", \"keZSjc1CaHTakP\")\n",
    "with GraphDatabase.driver(NEO4J_URI, auth=auth) as driver:\n",
    "    driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a27e75fddfaeba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to execute the query and return results as a pandas DataFrame\n",
    "def get_chat_logs_as_dataframe(driver):\n",
    "    query = \"\"\"\n",
    "    MATCH (m:Message)-[:POSTED_IN]->(c:Channel), (u:User)-[:SENT]->(m)\n",
    "    OPTIONAL MATCH (m)-[:MENTIONED]->(mentioned:User)\n",
    "    RETURN u.name AS user, c.name AS channel, m.timestamp AS timestamp, m.content AS message\n",
    "    ORDER BY m.timestamp DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        results = session.run(query)\n",
    "        \n",
    "        # Convert results to a DataFrame\n",
    "        chat_logs_df = pd.DataFrame([record.data() for record in results])\n",
    "        \n",
    "        # Optionally, you can save the DataFrame to a CSV file for easy use\n",
    "        chat_logs_df.to_csv(\"chat_logs.csv\", index=False)\n",
    "        \n",
    "        print(\"Chat logs saved to chat_logs.csv\")\n",
    "        \n",
    "        return chat_logs_df\n",
    "\n",
    "# Call the function to get chat logs as a pandas DataFrame\n",
    "chat_logs_df = get_chat_logs_as_dataframe(driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cc96315c51ea7c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Break the chat logs into conversational contexts\n",
    "\n",
    "## Possible Approaches:\n",
    "\n",
    "1. **Clustering**: Use Clustering algorithms to group the chat logs into conversational contexts,\n",
    "like K-Means or DBSCAN. We'll use the `message` column as the feature to cluster on.\n",
    "2. **Time-based**: Group chat logs based on a time window, like every 5 minutes.\n",
    "3. **User-based**: Group chat logs based on the user who sent the message.\n",
    "4. **Channel-based**: Group chat logs based on the channel where the message was posted.\n",
    "5. **Sequential**: Group chat logs based on the order they were posted.\n",
    "6. **Sequence Labeling**: Use Sequence Labeling models to predict the start and end of each conversation, like Named Entity Recognition (NER) models, Conditional Random Fields (CRFs), Hidden Markov Model (HMM) or Long Short-Term Memory (LSTM) networks to label each message with a conversation ID. To do this, we need to train our model on labeled data to learn the conversational patterns that distinguish between different conversational threads. We can use this model to label new messages automatically.\n",
    "7. **Transformer Based Methods**: Use transformer-based models like BERT, GPT-2, or RoBERTa to generate embeddings for each message and cluster them based on the embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing and Cleaning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f39bf6721f324724"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402d8fa16bbf26",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Basic text cleaning and preprocessing\n",
    "# You might want to expand this with more sophisticated cleaning\n",
    "chat_logs_df['message_clean'] = chat_logs_df['message'].str.lower().str.replace('[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Remove stop words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcb48559721da5e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2e96b2445caa154"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "chat_logs_df['message_clean'] = chat_logs_df['message_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e5a26b6ac3df09d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lemmatization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8cd6fd3e82d750fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return ' '.join([token.lemma_ for token in nlp(text)])\n",
    "\n",
    "chat_logs_df['message_clean'] = chat_logs_df['message_clean'].apply(lemmatize_text)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3eff047b0b725848",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing frequent but unimportant words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cecd0bd3855555ad"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# build frequent_words\n",
    "from collections import Counter\n",
    "\n",
    "# Tokenize the cleaned messages into lists of words\n",
    "chat_logs_df['tokens'] = chat_logs_df['message_clean'].str.split()\n",
    "\n",
    "# Flatten the list of token lists into a single list\n",
    "all_words = [word for tokens in chat_logs_df['tokens'] for word in tokens]\n",
    "\n",
    "# Count the words\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "# Set a frequency threshold\n",
    "frequency_threshold = 100  # This is just an example value\n",
    "\n",
    "# Filter words that meet or exceed the threshold\n",
    "frequent_words = {word for word, count in word_counts.items() if count >= frequency_threshold}\n",
    "\n",
    "chat_logs_df['message_clean'] = chat_logs_df['message_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in frequent_words]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8bb2b5a7ce4e8677",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing rare words"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1a6179a7ea3981f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set a frequency threshold for rare words\n",
    "#rare_threshold = 2  # Example: words appearing 2 times or less\n",
    "\n",
    "# Filter words that are equal to or below the threshold\n",
    "#rare_words = {word for word, count in word_counts.items() if count <= rare_threshold}\n",
    "\n",
    "#chat_logs_df['message_clean'] = chat_logs_df['message_clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in rare_words]))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad0acc4961e0f0c7"
  },
  {
   "cell_type": "markdown",
   "id": "7635ad8036fa7397",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b5826dd17cc133",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings\n",
    "message_embeddings = model.encode(chat_logs_df['message_clean'].tolist(), show_progress_bar=True)\n",
    "print(\"Embeddings generated successfully!\")\n",
    "\n",
    "# verify the shape of the embeddings\n",
    "print(message_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c151f514a46873f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cluster the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39577374d77b0533",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "\n",
    "# Normalize embeddings to improve clustering\n",
    "message_embeddings_normalized = normalize(message_embeddings)\n",
    "\n",
    "# Clustering with HDBSCAN\n",
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5, gen_min_span_tree=True)\n",
    "cluster_labels = clusterer.fit_predict(message_embeddings_normalized)\n",
    "\n",
    "# Add cluster labels to your DataFrame\n",
    "chat_logs_df['cluster'] = cluster_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1af0feceb6a96",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analyze the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc71864cf3374d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Explore the number of messages per cluster\n",
    "print(chat_logs_df['cluster'].value_counts())\n",
    "\n",
    "# Inspect a specific cluster\n",
    "#print(chat_logs_df[chat_logs_df['cluster'] == 0])\n",
    "\n",
    "# Group the DataFrame by the 'cluster' column\n",
    "grouped_df = chat_logs_df.groupby('cluster')\n",
    "\n",
    "# Iterate through each group\n",
    "for cluster_label, group in grouped_df:\n",
    "    print(f\"Cluster: {cluster_label}\")\n",
    "    print(group)  # 'group' is a DataFrame containing only the rows from this cluster\n",
    "    # You can perform further analysis or processing on each group here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b8cf1ffff4919",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
